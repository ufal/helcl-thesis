
* Evaluation methodologies in non-autoregressive papers


 | paper                                                       | CPU / GPU | batched decoding | report                                                            | notes                                                                                     |
 |-------------------------------------------------------------+-----------+------------------+-------------------------------------------------------------------+-------------------------------------------------------------------------------------------|
 | gu et al, non-autoreg                                       | GPU       | 1                | latency (avg over dataset), relative speedup                      |                                                                                           |
 | lee et al, deterministic                                    | both      | 1 ?              | tokens per second                                                 | "decoding efficiency is measured sentence-by-sentence"                                    |
 | fully NAT                                                   | both      |                  | speedup in comparison table, latency and speedup in their results | contains plot showing pareto frontier of BLEU/latency trade-off                           |
 | mask-predict (CMLM)                                         | GPU       | 10 sent.         | plot BLEU vs relative speedup, not really detailed                | both same implementation, AR use state caching (128.5s with, 210s without), NAR does not. |
 | AXE                                                         | dnr       | dnr              | they just say it is same speed as CMLM (their previous work)      |                                                                                           |
 | CTC (my)                                                    | both      | unclear :)       | do not compare speeds against others (gu and lee at the time)     |                                                                                           |
 | laNMT                                                       | GPU       | unclear          | avg latency incl std, relative speedup, compare rel. speedups     | they compare rel speedups local to a given publication; plot BLEU v. speedup tradeoff     |
 | latent transformer                                          | GPU       | 1 or 64          | latency (avg over dataset)                                        |                                                                                           |
 | NAT-REG nat with aux prediction (wang2019nonautoregressive) | GPU       | 1                | latency (avg over dataset), relative speedup,                     | copy times from different papers, some reproduction                                       |
 | bag-of-ngrams  shao2020minimizing                           | GPU       | unclear          | relative speedup, seconds-per-batch in one setting;               | compare relative speedups under different settings           (copy gu et al's 15,6x)      |
 | GLAT (qian et al 2008 glancing)                             | unclear   | unclear          | relative speedup,                                                 | no abs times; relative to numbers reported on different hardware                          |
 | flowSeq (ma et al)                                          | GPU       | varying          | latency plots                                                     | plot batch size vs latency, length vs latency                                             |
 | imputer/ctc (saharia et al)                                 | unclear   | unclear          | relative speedup                                                  |                                                                                           |
 | JM-NAT                                                      | GPU       | 1                | latency, relative speedup                                         | copy times from different papers, some reproduction                                       |
 | hint-NAT                                                    | GPU       | 1                | latency, relative speedup                                         | some measured on reproduction, some copied (but absolute times, speedup computed here)    |
 | reorder-NAT                                                 | GPU       | 1                | relative speedup, NO latency                                      |                                                                                           |
 |-------------------------------------------------------------+-----------+------------------+-------------------------------------------------------------------+-------------------------------------------------------------------------------------------|


 ** Notes

   - CMLM: the absolute numbers can be reconstructed using the information in
     the paper. (i.e. assuming that rel. speedup 1x is 128.5 seconds).

   - noisy parallel decoding: create many candidates, rescore using AR
     transformer (scoring is cheap with transformer).

   - in flowseq, they find that increased batch size helps non-autoregressive
     models more than it helps autoregressive models

   - insertion transformer, kermit, SMART, do not report latency

   - even though mostly single GPU with batch size 1, the GPUs themselves
     differ, so is the underlying hardware the research teams have at their
     disposal


* AR Baselines

  | paper                 | architecture       | copied?       | score wmt14 ende | score wmt14 deen |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Vaswani et al         | base beam 4        |               |            27.30 |              N/A |
  |                       | big  beam 4        |               |            28.40 |              N/A |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Gu et al              | base, greedy       |               |            22.71 |            26.39 |
  |                       | base, beam 4       |               |            23.45 |            27.02 |
  | Lee et al             | base, greedy       |               |            23.77 |            28.15 |
  |                       | base, beam 4       |               |            24.57 |            28.47 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | fully NAT             | base ?             |               |            27.48 |            31.39 |
  |                       | base 12-1 ?        |               |            26.21 |            30.80 |
  | * unclear if beam     | base 12-1 + KD ?   |               |            27.34 |            30.95 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | mask-predict          | base beam 4        | vaswani       |            27.30 |                  |
  |                       | base               |               |            27.74 |            31.09 |
  |                       | base + KD          |               |            27.86 |            31.07 |
  |                       | big  beam 4        | vaswani       |            28.40 |                  |
  |                       | big                |               |            28.60 |            31.71 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | AXE                   | base beam 5        |               |            27.61 |            31.38 |
  |                       | base b5 + KD       |               |            27.75 |            31.30 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | LaNMT                 | base               |               |            25.60 |                  |
  |                       | base, beam 3       |               |            26.10 |                  |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Latent Transformer    | base beam 4        | vaswani       |            27.30 |                  |
  |                       | base beam 4        | gu et al      |             23.5 |                  |
  |                       | base               | gu et al      |             22.7 |                  |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | NAT-REG               | base beam 4        | gu et al      |            23.45 |            27.02 |
  |                       | base beam 4        | lee et al     |            24.57 |            28.47 |
  |                       | base beam 4        | LT -> vaswani |             27.3 |                  |
  |                       | base beam 4        |               |             27.3 |            31.29 |
  |                       | weakened bb4       |               |            24.50 |                  |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Bag-of-ngrams         | base greedy        | lee et al     |            23.77 |            28.15 |
  | * UNDISCLOSED COPYING | base beam          | lee et al     |            24.57 |            28.47 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | GLAT                  | base beam 4        | vaswani       |            27.30 |                  |
  | * unclear if beam     | base ?             |               |            27.48 |            31.27 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | FlowSeq               | base beam 4        | vaswani       |            27.30 |                  |
  | * beam might be 5     | base beam 5 ?      |               |            27.16 |            31.44 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Saharia et al         | base ?             |               |             27.8 |             31.2 |
  | * unclear beam        | big ?              |               |             29.5 |             32.2 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | JM-NAT                | 6-6 512/512 ?      |               |            28.04 |            32.69 |
  | * unclear beam        | weakened base      |               |             27.4 |            31.29 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Hint-NAT              | LSTM               | ???           |            24.60 |                  |
  |                       | ConvS2S            | ???           |            26.43 |                  |
  | * kde vzali deen?     | base beam 4        | vaswani       |             27.3 |        31.29 ??? |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Reorder-NAT           | 6-6 512/512 beam 4 |               |            27.17 |            31.95 |
  |                       | 6-1 512/512 beam 4 |               |            25.52 |            29.31 |
  |                       | 6-gru 512/512 b4   |               |            26.27 |            30.62 |
  |-----------------------+--------------------+---------------+------------------+------------------|
  | Huang                 | base               |               |            27.48 |            31.21 |
  |-----------------------+--------------------+---------------+------------------+------------------|




  Sometimes, base means 512/512. Original base is 512/2048
