% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\chapter{Conclusions}
\label{chap:conclusions}
% %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In this thesis, we explored the possibilities of non-autoregressive models for
neural machine translation.

We presented a comprehensive survey of the \JH{jako attemtpts ale jiny -
  pokusy, bidy, ...} which have been proposed in this quite recent and rapidly
developing field. \JH{mozna tady nejaky vyjmenovat, jako gu nebto lee,
  iterative refinemtn a alignmnent-based metody s dynamickym progrfamovanim}

We pointed out some of the drawbacks of the approaches, namely \JH{parhaps?
  the} comparing the results to weaker baselines both in terms of translation
quality and speed. Another weakness is potentially flawed evaluation
methodology when the conclusions rely only on reporting relative speed
improvements across different evaluation environment settings.

In the first of the two experimental chapters \JH{(In Chapter 4)} we proposed a
novel method for non-autoregressive machine translation based on connectionist
temporal classification, which has been adopted by the non-autoregressive
research community as one of the basic approaches. We show ...

In the final chapter of this thesis we aim at improving our ctc-based approach
by using knowledge distillation using a strong autoregressive teacher model.
We \JH{continue}

\paragraph{Future Work.}
\JH{One future work is to implement the quantization into the NAT models.}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "thesis"
%%% End:
